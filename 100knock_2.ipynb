{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'hlab2023-nlp100' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/m0chi1216/hlab2023-nlp100.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xj6Wp-r2_kb",
        "outputId": "258b08ab-3656-445b-8afa-796120502f41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rio_m\\OneDrive - 国立大学法人東海国立大学機構\\100knock\\hlab2023-nlp100\\hlab2023-nlp100\n"
          ]
        }
      ],
      "source": [
        "cd hlab2023-nlp100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hgTzA7r3JBC",
        "outputId": "413513f8-abae-491f-be8a-9713ad0c1a1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: a branch named 'suzuki' already exists\n"
          ]
        }
      ],
      "source": [
        "!git checkout -b suzuki origin/suzuki"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rio_m\\OneDrive - 国立大学法人東海国立大学機構\\100knock\\hlab2023-nlp100\n"
          ]
        }
      ],
      "source": [
        "cd c:\\Users\\rio_m\\OneDrive - 国立大学法人東海国立大学機構\\100knock\\hlab2023-nlp100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bobRKMP3RoQ",
        "outputId": "931a4dee-9b4c-4e7c-c953-28c1afb17456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SUMMARY: Dataset of references (urls) to news web pages\n",
            "\n",
            "DESCRIPTION: Dataset of references to news web pages collected from an online aggregator in the period from March 10 to August 10 of 2014. The resources are grouped into clusters that represent pages discussing the same news story. The dataset includes also references to web pages that point (has a link to) one of the news page in the collection.\n",
            "\n",
            "TAGS: web pages, news, aggregator, classification, clustering\n",
            "\n",
            "LICENSE: Public domain - Due to restrictions on content and use of the news sources, the corpus is limited to web references (urls) to web pages and does not include any text content. The references have been retrieved from the news aggregator through traditional web browsers. \n",
            "\n",
            "FILE ENCODING: UTF-8\n",
            "\n",
            "FORMAT: Tab delimited CSV files. \n",
            "\n",
            "DATA SHAPE AND STATS: 422937 news pages and divided up into:\n",
            "\n",
            "152746 \tnews of business category\n",
            "108465 \tnews of science and technology category\n",
            "115920 \tnews of business category\n",
            " 45615 \tnews of health category\n",
            "\n",
            "2076 clusters of similar news for entertainment category\n",
            "1789 clusters of similar news for science and technology category\n",
            "2019 clusters of similar news for business category\n",
            "1347 clusters of similar news for health category\n",
            "\n",
            "References to web pages containing a link to one news included in the collection are also included. They are represented as pairs of urls corresponding to 2-page browsing sessions. The collection includes 15516 2-page browsing sessions covering 946 distinct clusters divided up into:\n",
            "\n",
            "6091 2-page sessions for business category\n",
            "9425 2-page sessions for entertainment category\n",
            "\n",
            " \n",
            "\n",
            "CONTENT\n",
            "=======\n",
            "\n",
            "FILENAME #1: newsCorpora.csv (102.297.000 bytes)\n",
            "DESCRIPTION: News pages\n",
            "FORMAT: ID \\t TITLE \\t URL \\t PUBLISHER \\t CATEGORY \\t STORY \\t HOSTNAME \\t TIMESTAMP\n",
            "\n",
            "where:\n",
            "ID\t\tNumeric ID\n",
            "TITLE\t\tNews title \n",
            "URL\t\tUrl\n",
            "PUBLISHER\tPublisher name\n",
            "CATEGORY\tNews category (b = business, t = science and technology, e = entertainment, m = health)\n",
            "STORY\t\tAlphanumeric ID of the cluster that includes news about the same story\n",
            "HOSTNAME\tUrl hostname\n",
            "TIMESTAMP \tApproximate time the news was published, as the number of milliseconds since the epoch 00:00:00 GMT, January 1, 1970\n",
            "\n",
            "\n",
            "FILENAME #2: 2pageSessions.csv (3.049.986 bytes)\n",
            "DESCRIPTION: 2-page sessions\n",
            "FORMAT: STORY \\t HOSTNAME \\t CATEGORY \\t URL\n",
            "\n",
            "where:\n",
            "STORY\t\tAlphanumeric ID of the cluster that includes news about the same story\n",
            "HOSTNAME\tUrl hostname\n",
            "CATEGORY\tNews category (b = business, t = science and technology, e = entertainment, m = health)\n",
            "URL\t\tTwo space-delimited urls representing a browsing session\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(\"readme.txt\",\"r\")as fp:\n",
        "  words=fp.read()\n",
        "  print(words)\n",
        "  fp.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\rio_m\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rio_m\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rio_m\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\rio_m\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\rio_m\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\rio_m\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\rio_m\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.2)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\rio_m\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\rio_m\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rio_m\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rio_m\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install scikit-learn "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgWyZkOT3sX7",
        "outputId": "aeef9a0d-ea11-4072-b487-22fb36f20304"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "学習データ\n",
            "CATEGORY\n",
            "b    4502\n",
            "e    4223\n",
            "t    1219\n",
            "m     728\n",
            "Name: count, dtype: int64\n",
            "検証データ\n",
            "CATEGORY\n",
            "b    563\n",
            "e    528\n",
            "t    152\n",
            "m     91\n",
            "Name: count, dtype: int64\n",
            "評価データ\n",
            "CATEGORY\n",
            "b    562\n",
            "e    528\n",
            "t    153\n",
            "m     91\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('./newsCorpora.csv',header=None, sep='\\t', names=['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n",
        "df=df.loc[df['PUBLISHER'].isin(['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']),['TITLE', 'CATEGORY']]\n",
        "\n",
        "train,valid=train_test_split(df,test_size=0.2,random_state=1,shuffle=True,stratify=df[\"CATEGORY\"])\n",
        "valid,test=train_test_split(valid,test_size=0.5,random_state=1,shuffle=True,stratify=valid[\"CATEGORY\"])\n",
        "\n",
        "train.to_csv('./train.txt', sep='\\t', index=False)\n",
        "valid.to_csv('./valid.txt', sep='\\t', index=False)\n",
        "test.to_csv('./test.txt', sep='\\t', index=False)\n",
        "\n",
        "print('学習データ')\n",
        "print(train['CATEGORY'].value_counts())\n",
        "print('検証データ')\n",
        "print(valid['CATEGORY'].value_counts())\n",
        "print('評価データ')\n",
        "print(test['CATEGORY'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "z_yZya-v4h7s"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "def preprocessing(text):\n",
        "  table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "  text = text.translate(table)  # 記号をスペースに置換\n",
        "  text = text.lower()  # 小文字化\n",
        "  text = re.sub('[0-9]+', '0', text)  # 数字列を0に置換\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX8myHzR9Vdb",
        "outputId": "3de5c886-6678-4c2f-8801-a248867a6d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               TITLE CATEGORY\n",
            "0  corrected update 0 brent crude falls again as ...        b\n",
            "1  corrected retailer michaels stores confirms pa...        b\n",
            "2  britney spears hits her local supermarket dres...        e\n",
            "3  orders propel us service industries as sales i...        b\n",
            "4  column fed to widen main st wall st gap  james...        b\n"
          ]
        }
      ],
      "source": [
        "df=pd.concat([train,valid,test])\n",
        "df.reset_index(drop=True,inplace=True)\n",
        "df[\"TITLE\"]=df[\"TITLE\"].map(lambda x:preprocessing(x))\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIWkTyk897Qb",
        "outputId": "2abbb854-ff47-460a-b712-6e7ddd6c6358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   0th  about  above  action  actor  adds  affirms  africa     after    again  \\\n",
            "0  0.0    0.0    0.0     0.0    0.0   0.0      0.0     0.0  0.000000  0.33371   \n",
            "1  0.0    0.0    0.0     0.0    0.0   0.0      0.0     0.0  0.000000  0.00000   \n",
            "2  0.0    0.0    0.0     0.0    0.0   0.0      0.0     0.0  0.425078  0.00000   \n",
            "3  0.0    0.0    0.0     0.0    0.0   0.0      0.0     0.0  0.000000  0.00000   \n",
            "4  0.0    0.0    0.0     0.0    0.0   0.0      0.0     0.0  0.000000  0.00000   \n",
            "\n",
            "   ...  yellen  yen  yet  yields  york  you  young  your  zac  zone  \n",
            "0  ...     0.0  0.0  0.0     0.0   0.0  0.0    0.0   0.0  0.0   0.0  \n",
            "1  ...     0.0  0.0  0.0     0.0   0.0  0.0    0.0   0.0  0.0   0.0  \n",
            "2  ...     0.0  0.0  0.0     0.0   0.0  0.0    0.0   0.0  0.0   0.0  \n",
            "3  ...     0.0  0.0  0.0     0.0   0.0  0.0    0.0   0.0  0.0   0.0  \n",
            "4  ...     0.0  0.0  0.0     0.0   0.0  0.0    0.0   0.0  0.0   0.0  \n",
            "\n",
            "[5 rows x 682 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "train_valid = df[:len(train) + len(valid)]\n",
        "test = df[len(train) + len(valid):]\n",
        "\n",
        "vec_tfidf=TfidfVectorizer(min_df=30)\n",
        "X_train_valid = vec_tfidf.fit_transform(train_valid['TITLE']) \n",
        "X_test = vec_tfidf.transform(test['TITLE'])\n",
        "\n",
        "X_train_valid = pd.DataFrame(X_train_valid.toarray(),columns=vec_tfidf.get_feature_names_out())\n",
        "X_test = pd.DataFrame(X_test.toarray(), columns=vec_tfidf.get_feature_names_out())\n",
        "\n",
        "X_train=X_train_valid[:len(train)]\n",
        "X_valid=X_train_valid[len(train):]\n",
        "\n",
        "print(X_train.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "2wvOSfbfHAYS",
        "outputId": "da8b5b4f-eac4-4240-f8b1-e64e4f86d981"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, random_state=123)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(max_iter=10000, random_state=123)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lg = LogisticRegression(random_state=123, max_iter=10000)\n",
        "lg.fit(X_train, train['CATEGORY'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "KnB6xEEEK3g7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def score(lg,x):\n",
        "  return[np.max(lg.predict_proba(x),axis=1),lg.predict(x)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtauOQbVMo4L",
        "outputId": "5ccc75c1-b3c6-484a-a25e-f0fa14ea9ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([0.94465832, 0.53412461, 0.74239951, ..., 0.96803602, 0.66861914,\n",
            "       0.92907688]), array(['b', 'b', 'e', ..., 'b', 'b', 'b'], dtype=object)]\n"
          ]
        }
      ],
      "source": [
        "train_predict=score(lg,X_train)\n",
        "test_predict=score(lg,X_test)\n",
        "print(train_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgJfX7tbM0I4",
        "outputId": "d0e5e8c6-e02a-4346-e005-2e0efb9e7ca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "学習データの正解率=0.868\n",
            "テストデータの正解率=0.827\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "train_accuracy=accuracy_score(train[\"CATEGORY\"],train_predict[1])\n",
        "test_accuracy=accuracy_score(test[\"CATEGORY\"],test_predict[1])\n",
        "\n",
        "print(f\"学習データの正解率={train_accuracy:.3f}\")\n",
        "print(f\"テストデータの正解率={test_accuracy:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvMVJ920OAS0",
        "outputId": "cb684b55-4a5a-466a-f7a2-54fd870dddd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch suzuki\n",
            "Your branch is up to date with 'origin/suzuki'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add/rm <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "  (commit or discard the untracked or modified content in submodules)\n",
            "\tdeleted:    100knock_2.ipynb\n",
            "\tmodified:   hlab2023-nlp100 (untracked content)\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "8GLkXUXFPROK"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"riors2020@gmail.com\"\n",
        "!git config --global user.name \"rio-user11\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git add ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khxMvm5nPkPM",
        "outputId": "90ee9d53-1ea2-43a2-d3b4-a9e8fa780fb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[suzuki 1786487] “commit2”\n",
            " 1 file changed, 627 deletions(-)\n",
            " delete mode 100644 100knock_2.ipynb\n"
          ]
        }
      ],
      "source": [
        "!git commit -m “commit2”\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "qtDcRel_QZXl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "remote: Resolving deltas:   0% (0/1)        \n",
            "remote: Resolving deltas: 100% (1/1)        \n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.        \n",
            "To https://github.com/m0chi1216/hlab2023-nlp100.git\n",
            "   3eae126..1786487  suzuki -> suzuki\n"
          ]
        }
      ],
      "source": [
        "!git push origin suzuki"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
