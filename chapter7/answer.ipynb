{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第7章: 単語ベクトル\n",
    "単語の意味を実ベクトルで表現する単語ベクトル（単語埋め込み）に関して，以下の処理を行うプログラムを作成せよ．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 60. 単語ベクトルの読み込みと表示\n",
    "Google Newsデータセット（約1,000億単語）での学習済み単語ベクトル（300万単語・フレーズ，300次元）をダウンロードし，”United States”の単語ベクトルを表示せよ．<br>ただし，”United States”は内部的には”United_States”と表現されていることに注意せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.61328125e-02, -4.83398438e-02,  2.35351562e-01,  1.74804688e-01,\n",
       "       -1.46484375e-01, -7.42187500e-02, -1.01562500e-01, -7.71484375e-02,\n",
       "        1.09375000e-01, -5.71289062e-02, -1.48437500e-01, -6.00585938e-02,\n",
       "        1.74804688e-01, -7.71484375e-02,  2.58789062e-02, -7.66601562e-02,\n",
       "       -3.80859375e-02,  1.35742188e-01,  3.75976562e-02, -4.19921875e-02,\n",
       "       -3.56445312e-02,  5.34667969e-02,  3.68118286e-04, -1.66992188e-01,\n",
       "       -1.17187500e-01,  1.41601562e-01, -1.69921875e-01, -6.49414062e-02,\n",
       "       -1.66992188e-01,  1.00585938e-01,  1.15722656e-01, -2.18750000e-01,\n",
       "       -9.86328125e-02, -2.56347656e-02,  1.23046875e-01, -3.54003906e-02,\n",
       "       -1.58203125e-01, -1.60156250e-01,  2.94189453e-02,  8.15429688e-02,\n",
       "        6.88476562e-02,  1.87500000e-01,  6.49414062e-02,  1.15234375e-01,\n",
       "       -2.27050781e-02,  3.32031250e-01, -3.27148438e-02,  1.77734375e-01,\n",
       "       -2.08007812e-01,  4.54101562e-02, -1.23901367e-02,  1.19628906e-01,\n",
       "        7.44628906e-03, -9.03320312e-03,  1.14257812e-01,  1.69921875e-01,\n",
       "       -2.38281250e-01, -2.79541016e-02, -1.21093750e-01,  2.47802734e-02,\n",
       "        7.71484375e-02, -2.81982422e-02, -4.71191406e-02,  1.78222656e-02,\n",
       "       -1.23046875e-01, -5.32226562e-02,  2.68554688e-02, -3.11279297e-02,\n",
       "       -5.59082031e-02, -5.00488281e-02, -3.73535156e-02,  1.25976562e-01,\n",
       "        5.61523438e-02,  1.51367188e-01,  4.29687500e-02, -2.08007812e-01,\n",
       "       -4.78515625e-02,  2.78320312e-02,  1.81640625e-01,  2.20703125e-01,\n",
       "       -3.61328125e-02, -8.39843750e-02, -3.69548798e-05, -9.52148438e-02,\n",
       "       -1.25000000e-01, -1.95312500e-01, -1.50390625e-01, -4.15039062e-02,\n",
       "        1.31835938e-01,  1.17675781e-01,  1.91650391e-02,  5.51757812e-02,\n",
       "       -9.42382812e-02, -1.08886719e-01,  7.32421875e-02, -1.15234375e-01,\n",
       "        8.93554688e-02, -1.40625000e-01,  1.45507812e-01,  4.49218750e-02,\n",
       "       -1.10473633e-02, -1.62353516e-02,  4.05883789e-03,  3.75976562e-02,\n",
       "       -6.98242188e-02, -5.46875000e-02,  2.17285156e-02, -9.47265625e-02,\n",
       "        4.24804688e-02,  1.81884766e-02, -1.73339844e-02,  4.63867188e-02,\n",
       "       -1.42578125e-01,  1.99218750e-01,  1.10839844e-01,  2.58789062e-02,\n",
       "       -7.08007812e-02, -5.54199219e-02,  3.45703125e-01,  1.61132812e-01,\n",
       "       -2.44140625e-01, -2.59765625e-01, -9.71679688e-02,  8.00781250e-02,\n",
       "       -8.78906250e-02, -7.22656250e-02,  1.42578125e-01, -8.54492188e-02,\n",
       "       -3.18359375e-01,  8.30078125e-02,  6.34765625e-02,  1.64062500e-01,\n",
       "       -1.92382812e-01, -1.17675781e-01, -5.41992188e-02, -1.56250000e-01,\n",
       "       -1.21582031e-01, -4.95605469e-02,  1.20117188e-01, -3.83300781e-02,\n",
       "        5.51757812e-02, -8.97216797e-03,  4.32128906e-02,  6.93359375e-02,\n",
       "        8.93554688e-02,  2.53906250e-01,  1.65039062e-01,  1.64062500e-01,\n",
       "       -1.41601562e-01,  4.58984375e-02,  1.97265625e-01, -8.98437500e-02,\n",
       "        3.90625000e-02, -1.51367188e-01, -8.60595703e-03, -1.17675781e-01,\n",
       "       -1.97265625e-01, -1.12792969e-01,  1.29882812e-01,  1.96289062e-01,\n",
       "        1.56402588e-03,  3.93066406e-02,  2.17773438e-01, -1.43554688e-01,\n",
       "        6.03027344e-02, -1.35742188e-01,  1.16210938e-01, -1.59912109e-02,\n",
       "        2.79296875e-01,  1.46484375e-01, -1.19628906e-01,  1.76757812e-01,\n",
       "        1.28906250e-01, -1.49414062e-01,  6.93359375e-02, -1.72851562e-01,\n",
       "        9.22851562e-02,  1.33056641e-02, -2.00195312e-01, -9.76562500e-02,\n",
       "       -1.65039062e-01, -2.46093750e-01, -2.35595703e-02, -2.11914062e-01,\n",
       "        1.84570312e-01, -1.85546875e-02,  2.16796875e-01,  5.05371094e-02,\n",
       "        2.02636719e-02,  4.25781250e-01,  1.28906250e-01, -2.77099609e-02,\n",
       "        1.29882812e-01, -1.15722656e-01, -2.05078125e-02,  1.49414062e-01,\n",
       "        7.81250000e-03, -2.05078125e-01, -8.05664062e-02, -2.67578125e-01,\n",
       "       -2.29492188e-02, -8.20312500e-02,  8.64257812e-02,  7.61718750e-02,\n",
       "       -3.66210938e-02,  5.22460938e-02, -1.22070312e-01, -1.44042969e-02,\n",
       "       -2.69531250e-01,  8.44726562e-02, -2.52685547e-02, -2.96630859e-02,\n",
       "       -1.68945312e-01,  1.93359375e-01, -1.08398438e-01,  1.94091797e-02,\n",
       "       -1.80664062e-01,  1.93359375e-01, -7.08007812e-02,  5.85937500e-02,\n",
       "       -1.01562500e-01, -1.31835938e-01,  7.51953125e-02, -7.66601562e-02,\n",
       "        3.37219238e-03, -8.59375000e-02,  1.25000000e-01,  2.92968750e-02,\n",
       "        1.70898438e-01, -9.37500000e-02, -1.09375000e-01, -2.50244141e-02,\n",
       "        2.11914062e-01, -4.44335938e-02,  6.12792969e-02,  2.62451172e-02,\n",
       "       -1.77734375e-01,  1.23046875e-01, -7.42187500e-02, -1.67968750e-01,\n",
       "       -1.08886719e-01, -9.04083252e-04, -7.37304688e-02,  5.49316406e-02,\n",
       "        6.03027344e-02,  8.39843750e-02,  9.17968750e-02, -1.32812500e-01,\n",
       "        1.22070312e-01, -8.78906250e-03,  1.19140625e-01, -1.94335938e-01,\n",
       "       -6.64062500e-02, -2.07031250e-01,  7.37304688e-02,  8.93554688e-02,\n",
       "        1.81884766e-02, -1.20605469e-01, -2.61230469e-02,  2.67333984e-02,\n",
       "        7.76367188e-02, -8.30078125e-02,  6.78710938e-02, -3.54003906e-02,\n",
       "        3.10546875e-01, -2.42919922e-02, -1.41601562e-01, -2.08007812e-01,\n",
       "       -4.57763672e-03, -6.54296875e-02, -4.95605469e-02,  2.22656250e-01,\n",
       "        1.53320312e-01, -1.38671875e-01, -5.24902344e-02,  4.24804688e-02,\n",
       "       -2.38281250e-01,  1.56250000e-01,  5.83648682e-04, -1.20605469e-01,\n",
       "       -9.22851562e-02, -4.44335938e-02,  3.61328125e-02, -1.86767578e-02,\n",
       "       -8.25195312e-02, -8.25195312e-02, -4.05273438e-02,  1.19018555e-02,\n",
       "        1.69921875e-01, -2.80761719e-02,  3.03649902e-03,  9.32617188e-02,\n",
       "       -8.49609375e-02,  1.57470703e-02,  7.03125000e-02,  1.62353516e-02,\n",
       "       -2.27050781e-02,  3.51562500e-02,  2.47070312e-01, -2.67333984e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 学習済みのWord2Vecモデルを読み込む\n",
    "model = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "model['United_States']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 61. 単語の類似度\n",
    "“United States”と”U.S.”のコサイン類似度を計算せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73107743"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('United_States', 'U.S.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 62. 類似度の高い単語10件\n",
    "“United States”とコサイン類似度が高い10語と，その類似度を出力せよ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Unites_States', 0.7877248525619507),\n",
       " ('Untied_States', 0.7541370987892151),\n",
       " ('United_Sates', 0.7400724291801453),\n",
       " ('U.S.', 0.7310774326324463),\n",
       " ('theUnited_States', 0.6404393911361694),\n",
       " ('America', 0.6178410053253174),\n",
       " ('UnitedStates', 0.6167312264442444),\n",
       " ('Europe', 0.6132988929748535),\n",
       " ('countries', 0.6044804453849792),\n",
       " ('Canada', 0.601906955242157)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('United_States', topn=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 63. 加法構成性によるアナロジー\n",
    "“Spain”の単語ベクトルから”Madrid”のベクトルを引き，”Athens”のベクトルを足したベクトルを計算し，<br>そのベクトルと類似度の高い10語とその類似度を出力せよ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Athens', 0.8415753841400146),\n",
       " ('Spain', 0.7456149458885193),\n",
       " ('Greece', 0.6866837739944458),\n",
       " ('Athens_Greece', 0.6324047446250916),\n",
       " ('Madrid', 0.5868974328041077),\n",
       " ('Thessaloniki', 0.5800884366035461),\n",
       " ('Mykonos_Island', 0.579736053943634),\n",
       " ('Portugal', 0.5660486817359924),\n",
       " ('Heraklio', 0.5607272386550903),\n",
       " ('Greeks', 0.5496171712875366)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ベクトルの計算によって\n",
    "vector = model['Spain'] - model['Madird'] + model['Athens']\n",
    "model.most_similar(vector, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Greece', 0.6015121340751648),\n",
       " ('Athens_Greece', 0.5763437151908875),\n",
       " ('Thessaloniki', 0.508480429649353),\n",
       " ('Greeks', 0.4871496558189392),\n",
       " ('Greek', 0.47021713852882385),\n",
       " ('Lithuania', 0.466966450214386),\n",
       " ('Mykonos_Island', 0.4635937809944153),\n",
       " ('Iraklion', 0.4567350149154663),\n",
       " ('Organising_Committee_ATHOC', 0.4564575254917145),\n",
       " ('Rome', 0.45040011405944824)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 単語の意味によって\n",
    "\n",
    "model.most_similar(positive=['Spain', 'Athens'], negative=['Madird'], topn=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 64. アナロジーデータでの実験\n",
    "単語アナロジーの評価データをダウンロードし，vec(2列目の単語) - vec(1列目の単語) + vec(3列目の単語)を計算し，<br>そのベクトルと類似度が最も高い単語と，その類似度を求めよ．<br>求めた単語と類似度は，各事例の末尾に追記せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('questions-words.txt', 'r') as f1, open('questions-words-add.txt', 'w') as f2:\n",
    "    for line in f1:\n",
    "        line = line.split()\n",
    "        if line[0] == ':':\n",
    "            category = line[1]\n",
    "        else:\n",
    "            word, val = model.most_similar(positive=[model[line[1]], model[line[2]]], negative=[model[line[0]]], topn=1)[0]\n",
    "            f2.write(' '.join([category] + line + [word, str(val) + '\\n']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
